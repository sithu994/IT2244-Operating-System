[root@DESKTOP-73GSIST ~]# vi list.csv
*Opens the list.csv file using the vi text editor for viewing or editing

[root@DESKTOP-73GSIST ~]# more list.csv
*Displays the contents of list.csv one screen at a time.

ID,Name,Age,Salary,Department
101,Alice,0,70000,Data Science
102,Bob,25,50000,Enginering
103,Charlie,5,80000,Data Science
104,David,40,90000,HR
105,Eva,28,60000,Enginering
106,Frank,38,75000,HR
107,Grace,27,72000,HR
108,Hank,32,68000,Enginering
109,Ivy,29,62000,Data Science
110,Jack,31,71000,HR

[root@DESKTOP-73GSIST ~]# tail -3 list.csv
*Shows the last 3 lines of the list.csv file.

108,Hank,32,68000,Enginering
109,Ivy,29,62000,Data Science
110,Jack,31,71000,HR

[root@DESKTOP-73GSIST ~]# awk -F, '{print NF;exist}' list.csv
*Prints the number of fields (NF) in each row using comma as the field separator.
Note: exist here has no effect; likely a typo or leftover.

5
5
5
5
5
5
5
5
5
5
5
[root@DESKTOP-73GSIST ~]# awk -F, '{print $3}' list.csv
*Prints the 3rd field (Age) from each row in list.csv.

Age
0
25
5
40
28
38
27
32
29
31

[root@DESKTOP-73GSIST ~]# cut -d, -f3 list.csv
*Extracts the 3rd field (Age) using comma as the delimiter.
Age
0
25
5
40
28
38
27
32
29
31
[root@DESKTOP-73GSIST ~]# cut -d, -f11 list.csv
*Tries to extract the 11th field, but nothing is printed since there are only 5 fields per row










[root@DESKTOP-73GSIST ~]# head -4 list.csv
*Displays the first 4 lines of list.csv.

ID,Name,Age,Salary,Department
101,Alice,0,70000,Data Science
102,Bob,25,50000,Enginering
103,Charlie,5,80000,Data Science

[root@DESKTOP-73GSIST ~]# head -n7 list.csv
*Shows the first 7 lines of list.csv.

ID,Name,Age,Salary,Department
101,Alice,0,70000,Data Science
102,Bob,25,50000,Enginering
103,Charlie,5,80000,Data Science
104,David,40,90000,HR
105,Eva,28,60000,Enginering
106,Frank,38,75000,HR

[root@DESKTOP-73GSIST ~]# head -n7 list.csv | tail -n1
*From the first 7 lines, prints only the 7th line using a pipeline.
106,Frank,38,75000,HR

[root@DESKTOP-73GSIST ~]# cut -d, -f4 list.csv
*Extracts the 4th field (Salary) using comma as the delimiter.
Salary
70000
50000
80000
90000
60000
75000
72000
68000
62000
71000

[root@DESKTOP-73GSIST ~]# awk -F, '{print $2, $3}' list.csv
*Prints the 2nd and 3rd fields (Name and Age) from each row.

Name Age
Alice 0
Bob 25
Charlie 5
David 40
Eva 28
Frank 38
Grace 27
Hank 32
Ivy 29
Jack 31

[root@DESKTOP-73GSIST ~]# cut d, -f4 list.csv
*Incorrect command: missing hyphen before -d, results in an error.

cut: d,: No such file or directory
ID,Name,Age,Salary,Department
101,Alice,0,70000,Data Science
102,Bob,25,50000,Enginering
103,Charlie,5,80000,Data Science
104,David,40,90000,HR
105,Eva,28,60000,Enginering
106,Frank,38,75000,HR
107,Grace,27,72000,HR
108,Hank,32,68000,Enginering
109,Ivy,29,62000,Data Science
110,Jack,31,71000,HR

[root@DESKTOP-73GSIST ~]# sort -t '-' -k4 -r list.csv
*Sorts list.csv in reverse (-r) order by the 4th field using dash (-) as delimiter.

ID,Name,Age,Salary,Department
110,Jack,31,71000,HR
109,Ivy,29,62000,Data Science
108,Hank,32,68000,Enginering
107,Grace,27,72000,HR
106,Frank,38,75000,HR
105,Eva,28,60000,Enginering
104,David,40,90000,HR
103,Charlie,5,80000,Data Science
102,Bob,25,50000,Enginering
101,Alice,0,70000,Data Science

[root@DESKTOP-73GSIST ~]# awk -F, '{print $4}' list.csv | sort
*Extracts the 4th field (Salary), then sorts the values in ascending order.

50000
60000
62000
68000
70000
71000
72000
75000
80000
90000
Salary

[root@DESKTOP-73GSIST ~]# sort -t '-' -k4 -r list.csv

ID,Name,Age,Salary,Department
110,Jack,31,71000,HR
109,Ivy,29,62000,Data Science
108,Hank,32,68000,Enginering
107,Grace,27,72000,HR
106,Frank,38,75000,HR
105,Eva,28,60000,Enginering
104,David,40,90000,HR
103,Charlie,5,80000,Data Science
102,Bob,25,50000,Enginering
101,Alice,0,70000,Data Science

[root@DESKTOP-73GSIST ~]# grep -v "Data Science" list.csv
*Prints all lines from list.csv that do not contain "Data Science".

ID,Name,Age,Salary,Department
102,Bob,25,50000,Enginering
104,David,40,90000,HR
105,Eva,28,60000,Enginering
106,Frank,38,75000,HR
107,Grace,27,72000,HR
108,Hank,32,68000,Enginering
110,Jack,31,71000,HR

[root@DESKTOP-73GSIST ~]# grep -v "Data Science" list.csv > temp_file.csv
*Writes all lines that do not contain "Data Science" to a new file temp_file.csv.

[root@DESKTOP-73GSIST ~]# sort -t',' -k4,4 -r list.csv
*Sorts list.csv in descending (-r) order based on the 4th field (Salary), using comma as the delimiter.

ID,Name,Age,Salary,Department
104,David,40,90000,HR
103,Charlie,5,80000,Data Science
106,Frank,38,75000,HR
107,Grace,27,72000,HR
110,Jack,31,71000,HR
101,Alice,0,70000,Data Science
108,Hank,32,68000,Enginering
109,Ivy,29,62000,Data Science
105,Eva,28,60000,Enginering
102,Bob,25,50000,Enginering

[root@DESKTOP-73GSIST ~]# sort -t',' -k4,4  -k2,2 -r list.csv
*Sorts list.csv in descending order first by 4th field (Salary), then by 2nd field (Name) for ties. Uses comma as delimiter.

ID,Name,Age,Salary,Department
104,David,40,90000,HR
103,Charlie,5,80000,Data Science
106,Frank,38,75000,HR
107,Grace,27,72000,HR
110,Jack,31,71000,HR
101,Alice,0,70000,Data Science
108,Hank,32,68000,Enginering
109,Ivy,29,62000,Data Science
105,Eva,28,60000,Enginering
102,Bob,25,50000,Enginering
[root@DESKTOP-73GSIST ~]#










































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































